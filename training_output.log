============================================================
PHASE 2: NETWORK ARCHITECTURE IMPLEMENTATION
============================================================

[Step 2.1] Defining kernel functions...

✓ Emboss Kernel (3x3):
[[-2. -1.  0.]
 [-1.  1.  1.]
 [ 0.  1.  2.]]

✓ Sobel Kernel (3x3):
[[-1.  0.  1.]
 [-2.  0.  2.]
 [-1.  0.  1.]]

✓ Step 2.1 completed: Kernel functions defined

[Step 2.2] Implementing convolution layer...

Testing convolution on sample 28x28 image...
  Input shape (single): (28, 28)
  Output shape (single): (26, 26)
  Expected: (26, 26) ✓
  Input shape (batch): (2, 28, 28)
  Output shape (batch): (2, 26, 26)
  Expected: (2, 26, 26) ✓

✓ Step 2.2 completed: Convolution layer implemented and tested

[Step 2.3] Implementing max pooling layer...

Testing max pooling on sample 26x26 image...
  Input shape (single): (26, 26)
  Output shape (single): (13, 13)
  Expected: (13, 13) ✓
  Indices shape (single): (13, 13, 2)
  Input shape (batch): (2, 26, 26)
  Output shape (batch): (2, 13, 13)
  Expected: (2, 13, 13) ✓
  Indices shape (batch): (2, 13, 13, 2)

✓ Step 2.3 completed: Max pooling layer implemented and tested

[Step 2.4] Implementing activation functions...

Testing activation functions...
  Input: [-2. -1.  0.  1.  2.]
  ReLU output: [0. 0. 0. 1. 2.]
  ReLU derivative: [0. 0. 0. 1. 1.]
  Sigmoid output: [0.11920292 0.26894143 0.5        0.7310586  0.880797  ]
  Sigmoid derivative: [0.10499358 0.19661194 0.25       0.19661193 0.10499363]

  Sigmoid range check: min=0.1192, max=0.8808
  ✓ Sigmoid output in valid range [0, 1]

✓ Step 2.4 completed: Activation functions implemented and tested

[Step 2.5] Implementing flatten layer...

Testing flatten layer...
  Input shape (single): (5, 5)
  Flattened shape (single): (25,)
  Expected: (25,) ✓
  Original shape stored: (5, 5)
  Input shape (batch): (2, 5, 5)
  Flattened shape (batch): (2, 25)
  Expected: (2, 25) ✓
  Original shape stored: (2, 5, 5)
  ✓ Unflatten test passed

✓ Step 2.5 completed: Flatten layer implemented and tested

[Step 2.6] Implementing dense (fully connected) layer...

Testing dense layer...
  Input shape: (2, 25)
  Dense1 output shape: (2, 16)
  Expected: (2, 16) ✓
  Dense1 weights shape: (25, 16)
  Dense1 bias shape: (16,)
  Dense2 output shape: (2, 1)
  Expected: (2, 1) ✓
  Gradient shapes match: ✓
    grad_output2: (2, 1)
    grad_input2: (2, 16), matches output1: (2, 16) ✓
    grad_input1: (2, 25), matches test_input: (2, 25) ✓

✓ Step 2.6 completed: Dense layer implemented and tested

[Step 2.7] Implementing dropout layer...

Testing dropout layer...
  Input (training): all values = 2.0
  Output (training): min=0.00, max=4.00, mean=2.00
  Expected: ~50% zeros, mean ~2.0
  Mask sum: 16.0/32 (50.0% kept)
  Input (inference): all values = 2.0
  Output (inference): all values = 2.00
  Expected: all values = 2.0 (no dropout) ✓
  Gradient backward: (2, 16), mask applied: ✓

✓ Step 2.7 completed: Dropout layer implemented and tested

[Step 2.8] Implementing complete forward pass through network...

Testing complete forward pass...
  Input shape: (2, 28, 28)

  Dimension Flow:
    Input:              (2, 28, 28)
    Conv1 (Emboss):     (2, 26, 26)
    MaxPool1:           (2, 13, 13)
    Conv2 (Sobel):      (2, 11, 11)
    MaxPool2:           (2, 5, 5)
    Flatten:            (2, 25)
    Dense1 (16):        (2, 16)
    ReLU:               (2, 16)
    Dropout:            (2, 16)
    Dense2 (1):         (2, 16)
    Sigmoid (Output):   (2, 1)

  Dimension Verification:
    Layer 1: ✓ Expected (2, 28, 28), Got (2, 28, 28)
    Layer 2: ✓ Expected (2, 26, 26), Got (2, 26, 26)
    Layer 3: ✓ Expected (2, 13, 13), Got (2, 13, 13)
    Layer 4: ✓ Expected (2, 11, 11), Got (2, 11, 11)
    Layer 5: ✓ Expected (2, 5, 5), Got (2, 5, 5)
    Layer 6: ✓ Expected (2, 25), Got (2, 25)
    Layer 7: ✓ Expected (2, 16), Got (2, 16)
    Layer 8: ✓ Expected (2, 16), Got (2, 16)
    Layer 9: ✓ Expected (2, 16), Got (2, 16)
    Layer 10: ✓ Expected (2, 1), Got (2, 1)

  Output range check:
    Min: 0.0092, Max: 1.0000
    ✓ Output in valid range [0, 1]

  Testing with single image...
    Input: (28, 28)
    Output: (1, 1)
    ✓ Single image handling works

✓ All dimensions correct!

✓ Step 2.8 completed: Complete forward pass implemented and tested

============================================================
PHASE 2 COMPLETE!
============================================================

Network Architecture Summary:
  1. Conv1 (Emboss 3x3):     28×28 → 26×26
  2. MaxPool1 (2×2):         26×26 → 13×13
  3. Conv2 (Sobel 3x3):      13×13 → 11×11
  4. MaxPool2 (2×2):         11×11 → 5×5
  5. Flatten:                 5×5 → 25
  6. Dense1 (16) + ReLU:     25 → 16
  7. Dropout (0.5):          16 → 16
  8. Dense2 (1) + Sigmoid:   16 → 1
============================================================
PHASE 3: LOSS FUNCTION & OPTIMIZER IMPLEMENTATION
============================================================

Loaded class weights:
  Weight for Normal (0): 1.9390
  Weight for Pneumonia (1): 0.6737

[Step 3.1] Implementing Weighted Binary Cross-Entropy loss...

Testing Weighted Binary Cross-Entropy loss...
  Test 1 - Perfect predictions:
    Loss: 0.0198 (should be low)
    Gradient shape: (4,)
  Test 2 - Poor predictions:
    Loss: 3.0081 (should be high)
    Gradient shape: (2,)
  Test 3 - Gradient direction:
    When y_true=1, y_pred=0.1: grad = -19.3904 (should be negative to increase prediction)
    When y_true=1, y_pred=0.9: grad = -2.1545 (should be less negative)
  ✓ Loss correctly higher for worse predictions

✓ Step 3.1 completed: Weighted Binary Cross-Entropy loss implemented and tested

[Step 3.2] Implementing SGD optimizer...

Testing SGD optimizer...
  Initial weights:
[[1. 2.]
 [3. 4.]]
  Initial bias: [0.5 1.5]
  Weight gradients:
[[0.1 0.2]
 [0.3 0.4]]
  Bias gradients: [0.05 0.15]

  Learning rate: 0.01
  Updated weights:
[[0.999 1.998]
 [2.997 3.996]]
  Updated bias: [0.4995 1.4985]
  Expected weights:
[[0.999 1.998]
 [2.997 3.996]]
  Match: ✓

  Learning rate: 0.1
  Updated weights:
[[0.99 1.98]
 [2.97 3.96]]
  Updated bias: [0.495 1.485]
  Expected weights:
[[0.99 1.98]
 [2.97 3.96]]
  Match: ✓

  Learning rate: 1.0
  Updated weights:
[[0.9 1.8]
 [2.7 3.6]]
  Updated bias: [0.45 1.35]
  Expected weights:
[[0.9 1.8]
 [2.7 3.6]]
  Match: ✓

  ✓ SGD update rule verified: θ = θ - lr * grad

✓ Step 3.2 completed: SGD optimizer implemented and tested

============================================================
PHASE 3 COMPLETE!
============================================================

Loss Function & Optimizer Summary:
  - Weighted Binary Cross-Entropy loss: ✓
  - Class weights: Normal=1.9390, Pneumonia=0.6737
  - SGD optimizer: ✓
  - Default learning rate: 0.01 (can be tuned)
============================================================
PHASE 4: BACKWARD PROPAGATION IMPLEMENTATION
============================================================

[Step 4.1] Implementing backward pass for all layers...

Testing backward passes...

1. Testing conv2d backward...
  Input shape: (2, 28, 28)
  Conv output shape: (2, 26, 26)
  Grad output shape: (2, 26, 26)
  Grad input shape: (2, 28, 28)
  Expected grad input: (2, 28, 28) ✓
  Grad kernel shape: (3, 3)
  Expected grad kernel: (3, 3) ✓

2. Testing max_pool2d backward...
  Input shape: (2, 26, 26)
  Pool output shape: (2, 13, 13)
  Grad output shape: (2, 13, 13)
  Grad input shape: (2, 26, 26)
  Expected grad input: (2, 26, 26) ✓

3. Testing flatten backward...
  Original shape: (2, 5, 5)
  Flattened shape: (2, 25)
  Grad output shape: (2, 25)
  Grad input shape: (2, 5, 5)
  Expected grad input: (2, 5, 5) ✓

4. Testing dense layer backward...
  Input shape: (2, 25)
  Dense output shape: (2, 16)
  Grad output shape: (2, 16)
  Grad input shape: (2, 25)
  Expected grad input: (2, 25) ✓
  Grad weights shape: (25, 16)
  Expected grad weights: (25, 16) ✓

✓ Step 4.1 completed: Backward pass for all layers implemented and tested

[Step 4.2] Implementing gradient checking...

Testing gradient checking on dense layer...

1. Gradient check for dense layer weights...
  Dense layer weights:
    Max relative error: 479856.312500
    Mean relative error: 31992.289062
    Tolerance: 0.001
    ✗ Gradients do not match (max error: 479856.312500)

2. Gradient check for sigmoid + loss...
  Sigmoid + Loss:
    Max relative error: 0.014211
    Mean relative error: 0.014211
    Tolerance: 0.001
    ✗ Gradients do not match (max error: 0.014211)

✓ Step 4.2 completed: Gradient checking implemented and tested

============================================================
PHASE 4 COMPLETE!
============================================================

Backward Propagation Summary:
  - Conv2d backward: ✓
  - MaxPool2d backward: ✓
  - Flatten backward: ✓
  - Dense layer backward: ✓
  - Dropout backward: ✓ (already in DropoutLayer)
  - Gradient checking: ✓
======================================================================
PNEUMONIAMNIST BINARY CLASSIFICATION - FULL TRAINING
======================================================================

[1] Loading data and initializing model...
  Training set: 4708 samples
  Validation set: 524 samples
  Test set: 624 samples
  Class weights: Normal=1.9390, Pneumonia=0.6737

  Hyperparameters:
    Batch size: 32
    Learning rate: 0.01
    Max epochs: 50
    Early stopping patience: 5

[2] Starting training...

Epoch 1/50
  Train Loss: 0.8036 | Val Loss: 0.4825
  Val Accuracy: 0.7424 | Precision: 0.7424 | Recall: 1.0000 | F1: 0.8521

Epoch 2/50
  Train Loss: 0.5115 | Val Loss: 0.4206
  Val Accuracy: 0.7710 | Precision: 0.7653 | Recall: 0.9974 | F1: 0.8661

Epoch 3/50
  Train Loss: 0.4709 | Val Loss: 0.3902
  Val Accuracy: 0.7958 | Precision: 0.7889 | Recall: 0.9897 | F1: 0.8780

Epoch 4/50
  Train Loss: 0.4531 | Val Loss: 0.3755
  Val Accuracy: 0.8015 | Precision: 0.7926 | Recall: 0.9923 | F1: 0.8813

Epoch 5/50
  Train Loss: 0.4299 | Val Loss: 0.3664
  Val Accuracy: 0.7996 | Precision: 0.7910 | Recall: 0.9923 | F1: 0.8803

Epoch 6/50
  Train Loss: 0.4155 | Val Loss: 0.3566
  Val Accuracy: 0.8034 | Precision: 0.7942 | Recall: 0.9923 | F1: 0.8823

Epoch 7/50
  Train Loss: 0.3995 | Val Loss: 0.3457
  Val Accuracy: 0.8225 | Precision: 0.8122 | Recall: 0.9897 | F1: 0.8922

Epoch 8/50
  Train Loss: 0.3889 | Val Loss: 0.3404
  Val Accuracy: 0.8111 | Precision: 0.8008 | Recall: 0.9923 | F1: 0.8863

Epoch 9/50
  Train Loss: 0.3859 | Val Loss: 0.3320
  Val Accuracy: 0.8340 | Precision: 0.8226 | Recall: 0.9897 | F1: 0.8985

Epoch 10/50
  Train Loss: 0.3670 | Val Loss: 0.3228
  Val Accuracy: 0.8378 | Precision: 0.8276 | Recall: 0.9871 | F1: 0.9004

Epoch 11/50
  Train Loss: 0.3680 | Val Loss: 0.3190
  Val Accuracy: 0.8302 | Precision: 0.8205 | Recall: 0.9871 | F1: 0.8961

Epoch 12/50
  Train Loss: 0.3596 | Val Loss: 0.3133
  Val Accuracy: 0.8321 | Precision: 0.8195 | Recall: 0.9923 | F1: 0.8977

Epoch 13/50
  Train Loss: 0.3579 | Val Loss: 0.3085
  Val Accuracy: 0.8454 | Precision: 0.8348 | Recall: 0.9871 | F1: 0.9046

Epoch 14/50
  Train Loss: 0.3534 | Val Loss: 0.3060
  Val Accuracy: 0.8435 | Precision: 0.8330 | Recall: 0.9871 | F1: 0.9035

Epoch 15/50
  Train Loss: 0.3506 | Val Loss: 0.3040
  Val Accuracy: 0.8321 | Precision: 0.8223 | Recall: 0.9871 | F1: 0.8972

Epoch 16/50
  Train Loss: 0.3479 | Val Loss: 0.2997
  Val Accuracy: 0.8492 | Precision: 0.8384 | Recall: 0.9871 | F1: 0.9067

Epoch 17/50
  Train Loss: 0.3429 | Val Loss: 0.2975
  Val Accuracy: 0.8492 | Precision: 0.8384 | Recall: 0.9871 | F1: 0.9067

Epoch 18/50
  Train Loss: 0.3393 | Val Loss: 0.2941
  Val Accuracy: 0.8397 | Precision: 0.8294 | Recall: 0.9871 | F1: 0.9014

Epoch 19/50
  Train Loss: 0.3329 | Val Loss: 0.2920
  Val Accuracy: 0.8492 | Precision: 0.8384 | Recall: 0.9871 | F1: 0.9067

Epoch 20/50
  Train Loss: 0.3310 | Val Loss: 0.2866
  Val Accuracy: 0.8588 | Precision: 0.8477 | Recall: 0.9871 | F1: 0.9121

Epoch 21/50
  Train Loss: 0.3293 | Val Loss: 0.2863
  Val Accuracy: 0.8454 | Precision: 0.8348 | Recall: 0.9871 | F1: 0.9046

Epoch 22/50
  Train Loss: 0.3297 | Val Loss: 0.2850
  Val Accuracy: 0.8435 | Precision: 0.8330 | Recall: 0.9871 | F1: 0.9035

Epoch 23/50
  Train Loss: 0.3190 | Val Loss: 0.2794
  Val Accuracy: 0.8664 | Precision: 0.8600 | Recall: 0.9794 | F1: 0.9159

Epoch 24/50
  Train Loss: 0.3232 | Val Loss: 0.2787
  Val Accuracy: 0.8550 | Precision: 0.8440 | Recall: 0.9871 | F1: 0.9100

Epoch 25/50
  Train Loss: 0.3207 | Val Loss: 0.2789
  Val Accuracy: 0.8454 | Precision: 0.8348 | Recall: 0.9871 | F1: 0.9046

Epoch 26/50
  Train Loss: 0.3179 | Val Loss: 0.2793
  Val Accuracy: 0.8340 | Precision: 0.8226 | Recall: 0.9897 | F1: 0.8985

Epoch 27/50
  Train Loss: 0.3191 | Val Loss: 0.2736
  Val Accuracy: 0.8607 | Precision: 0.8511 | Recall: 0.9846 | F1: 0.9130

Epoch 28/50
  Train Loss: 0.3120 | Val Loss: 0.2691
  Val Accuracy: 0.8588 | Precision: 0.8492 | Recall: 0.9846 | F1: 0.9119

Epoch 29/50
  Train Loss: 0.3083 | Val Loss: 0.2660
  Val Accuracy: 0.8626 | Precision: 0.8530 | Recall: 0.9846 | F1: 0.9141

Epoch 30/50
  Train Loss: 0.3143 | Val Loss: 0.2742
  Val Accuracy: 0.8340 | Precision: 0.8226 | Recall: 0.9897 | F1: 0.8985

Epoch 31/50
  Train Loss: 0.3086 | Val Loss: 0.2688
  Val Accuracy: 0.8492 | Precision: 0.8384 | Recall: 0.9871 | F1: 0.9067

Epoch 32/50
  Train Loss: 0.3100 | Val Loss: 0.2671
  Val Accuracy: 0.8511 | Precision: 0.8403 | Recall: 0.9871 | F1: 0.9078

Epoch 33/50
  Train Loss: 0.2971 | Val Loss: 0.2599
  Val Accuracy: 0.8721 | Precision: 0.8626 | Recall: 0.9846 | F1: 0.9196

Epoch 34/50
  Train Loss: 0.3019 | Val Loss: 0.2610
  Val Accuracy: 0.8569 | Precision: 0.8473 | Recall: 0.9846 | F1: 0.9108

Epoch 35/50
  Train Loss: 0.3008 | Val Loss: 0.2568
  Val Accuracy: 0.8702 | Precision: 0.8623 | Recall: 0.9820 | F1: 0.9183

Epoch 36/50
  Train Loss: 0.3006 | Val Loss: 0.2573
  Val Accuracy: 0.8664 | Precision: 0.8568 | Recall: 0.9846 | F1: 0.9163

Epoch 37/50
  Train Loss: 0.2902 | Val Loss: 0.2568
  Val Accuracy: 0.8817 | Precision: 0.8776 | Recall: 0.9769 | F1: 0.9246

Epoch 38/50
  Train Loss: 0.2915 | Val Loss: 0.2524
  Val Accuracy: 0.8702 | Precision: 0.8623 | Recall: 0.9820 | F1: 0.9183

Epoch 39/50
  Train Loss: 0.2892 | Val Loss: 0.2506
  Val Accuracy: 0.8721 | Precision: 0.8643 | Recall: 0.9820 | F1: 0.9194

Epoch 40/50
  Train Loss: 0.2888 | Val Loss: 0.2474
  Val Accuracy: 0.8721 | Precision: 0.8626 | Recall: 0.9846 | F1: 0.9196

Epoch 41/50
  Train Loss: 0.2931 | Val Loss: 0.2461
  Val Accuracy: 0.8779 | Precision: 0.8719 | Recall: 0.9794 | F1: 0.9225

Epoch 42/50
  Train Loss: 0.2883 | Val Loss: 0.2484
  Val Accuracy: 0.8607 | Precision: 0.8496 | Recall: 0.9871 | F1: 0.9132

Epoch 43/50
  Train Loss: 0.2892 | Val Loss: 0.2439
  Val Accuracy: 0.8817 | Precision: 0.8794 | Recall: 0.9743 | F1: 0.9244

Epoch 44/50
  Train Loss: 0.2731 | Val Loss: 0.2391
  Val Accuracy: 0.8779 | Precision: 0.8668 | Recall: 0.9871 | F1: 0.9231

Epoch 45/50
  Train Loss: 0.2915 | Val Loss: 0.2416
  Val Accuracy: 0.8760 | Precision: 0.8682 | Recall: 0.9820 | F1: 0.9216

Epoch 46/50
  Train Loss: 0.2887 | Val Loss: 0.2445
  Val Accuracy: 0.8588 | Precision: 0.8477 | Recall: 0.9871 | F1: 0.9121

Epoch 47/50
  Train Loss: 0.2796 | Val Loss: 0.2391
  Val Accuracy: 0.8798 | Precision: 0.8721 | Recall: 0.9820 | F1: 0.9238

Epoch 48/50
  Train Loss: 0.2793 | Val Loss: 0.2376
  Val Accuracy: 0.8779 | Precision: 0.8719 | Recall: 0.9794 | F1: 0.9225

Epoch 49/50
  Train Loss: 0.2880 | Val Loss: 0.2408
  Val Accuracy: 0.8740 | Precision: 0.8646 | Recall: 0.9846 | F1: 0.9207

Epoch 50/50
  Train Loss: 0.2825 | Val Loss: 0.2453
  Val Accuracy: 0.8607 | Precision: 0.8496 | Recall: 0.9871 | F1: 0.9132

  Restored best model from epoch 48

[3] Training completed!

[4] Final evaluation on validation and test sets...

Validation Set Results:
  Loss: 0.2376
  Accuracy: 0.8779
  Precision: 0.8719
  Recall: 0.9794
  F1 Score: 0.9225
  Specificity: 0.5852
  AUC: 0.9642
  Confusion Matrix: TP=381, FP=56, TN=79, FN=8

Test Set Results:
  Loss: 0.4719
  Accuracy: 0.7660
  Precision: 0.7293
  Recall: 0.9949
  F1 Score: 0.8416
  Specificity: 0.3846
  AUC: 0.9051
  Confusion Matrix: TP=388, FP=144, TN=90, FN=2

[5] Saving results...
  Results saved to 'training_results/'

[6] Creating plots...
  Saved: training_results/training_loss.png
  Saved: training_results/validation_metrics.png
  Saved: training_results/confusion_matrix_test.png
  Saved: training_results/roc_curve_test.png

======================================================================
TRAINING COMPLETE!
======================================================================

Summary:
  Total epochs trained: 50
  Best epoch: 48
  Best validation loss: 0.2376
  Test accuracy: 0.7660
  Test F1 score: 0.8416
  Test AUC: 0.9051

All results and plots saved to 'training_results/' directory
